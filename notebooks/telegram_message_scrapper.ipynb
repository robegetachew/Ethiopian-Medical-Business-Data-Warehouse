{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Task 1 - Data scraping and collection pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install telethon python-dotenv pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply nest_asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "#  Import required libraries\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from telethon.sync import TelegramClient\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment variables loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "#  Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "api_id = os.getenv(\"TELEGRAM_API_ID\")\n",
    "api_hash = os.getenv(\"TELEGRAM_API_HASH\")\n",
    "phone_number = os.getenv(\"TELEGRAM_PHONE_NUMBER\")\n",
    "\n",
    "if api_id and api_hash and phone_number:\n",
    "    print(\"‚úÖ Environment variables loaded successfully!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Warning: Missing environment variables. Check your .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Log directory: logs\n",
      "üìÇ Messages storage: scraped_messages.csv\n"
     ]
    }
   ],
   "source": [
    "# Set up logging and storage paths\n",
    "CURRENT_DIR = os.path.abspath(os.getcwd())\n",
    "PROJECT_ROOT = os.path.dirname(CURRENT_DIR)\n",
    "\n",
    "log_dir = os.path.join(PROJECT_ROOT, \"logs\")\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "log_storage= os.path.join(\"logs\")\n",
    "\n",
    "log_file = os.path.join(log_dir, \"scraping.log\")\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "TEXT_DATA_DIR = os.path.join(PROJECT_ROOT, \"data\", \"messages\")\n",
    "os.makedirs(TEXT_DATA_DIR, exist_ok=True)\n",
    "text_data_path = os.path.join(TEXT_DATA_DIR, \"scraped_messages.csv\")\n",
    "text_storage= os.path.join(\"scraped_messages.csv\")\n",
    "\n",
    "if not os.path.exists(text_data_path):\n",
    "    pd.DataFrame(columns=[\"channel_name\",\"channel_title\", \"date\", \"text\"]).to_csv(text_data_path, index=False)\n",
    "\n",
    "print(f\"üìÇ Log directory: {log_storage}\")\n",
    "print(f\"üìÇ Messages storage: {text_storage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Telegram client initialized!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Telegram client\n",
    "client = TelegramClient(\"session_name\", api_id, api_hash)\n",
    "print(\"üöÄ Telegram client initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Message Scrapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for scraping messages\n",
    "async def scrape_messages():\n",
    "    \"\"\"Scrape messages from Telegram channels and save to CSV\"\"\"\n",
    "    await client.start(phone_number)\n",
    "\n",
    "    channels = [\n",
    "        \"https://t.me/DoctorsET\",\n",
    "        \"https://t.me/CheMed123\",\n",
    "        \"https://t.me/lobelia4cosmetics\",\n",
    "        \"https://t.me/yetenaweg\",\n",
    "        \"https://t.me/EAHCI\"\n",
    "    ]\n",
    "\n",
    "    all_messages = []\n",
    "    for channel in channels:\n",
    "        try:\n",
    "            entity = await client.get_entity(channel)\n",
    "            channel_name = entity.username if entity.username else \"N/A\"\n",
    "            channel_title = entity.title  \n",
    "            messages = await client.get_messages(entity, limit=700)\n",
    "\n",
    "            for msg in messages:\n",
    "                all_messages.append({\n",
    "                    \"channel_name\": channel_name,\n",
    "                    \"channel_title\": channel_title,\n",
    "                    \"date\": msg.date.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                    \"text\": msg.text if msg.text else \"[No Text]\"\n",
    "                })\n",
    "\n",
    "            logging.info(f\"‚úÖ Scraped {len(messages)} messages from {channel_title} ({channel_name})\")\n",
    "            print(f\"‚úÖ Scraped {len(messages)} messages from {channel_title} ({channel_name})\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error scraping {channel}: {e}\")\n",
    "            print(f\"‚ùå Error scraping {channel}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(all_messages)\n",
    "    if not df.empty:\n",
    "        df.to_csv(text_data_path, mode=\"a\", header=False, index=False)\n",
    "        logging.info(\"Messages saved successfully!\")\n",
    "        print(\"üìå Messages saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Image Scrapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for scraping images\n",
    "async def scrape_images():\n",
    "    \"\"\"Scrape images from Telegram channels and save locally\"\"\"\n",
    "    await client.start(phone_number)\n",
    "\n",
    "    IMAGE_FOLDER = os.path.join(PROJECT_ROOT, \"data\", \"images\")\n",
    "    os.makedirs(IMAGE_FOLDER, exist_ok=True)\n",
    "\n",
    "    image_channels = [\"https://t.me/CheMed123\", \"https://t.me/lobelia4cosmetics\"]\n",
    "\n",
    "    for channel in image_channels:\n",
    "        try:\n",
    "            entity = await client.get_entity(channel)\n",
    "            messages = await client.get_messages(entity, limit=100)\n",
    "\n",
    "            for msg in messages:\n",
    "                if msg.photo:\n",
    "                    sanitized_channel = re.sub(\n",
    "                        r\"https://t.me/|[^a-zA-Z0-9_]\", \"_\", channel\n",
    "                    )\n",
    "                    formatted_date = msg.date.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "                    filename = os.path.join(\n",
    "                        IMAGE_FOLDER, f\"{sanitized_channel}_{formatted_date}.jpg\"\n",
    "                    )\n",
    "                    storage = os.path.join(f\"{sanitized_channel}_{formatted_date}.jpg\")\n",
    "\n",
    "                    await client.download_media(msg.photo, filename)\n",
    "                    logging.info(f\"Downloaded image from {channel} - {filename}\")\n",
    "                    print(f\"‚úÖ Image saved: {storage}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error scraping images from {channel}: {e}\")\n",
    "            print(f\"‚ùå Error scraping images from {channel}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting message scraping...\n",
      "‚úÖ Scraped 100 messages from Doctors Ethiopia (DoctorsET)\n",
      "‚úÖ Scraped 76 messages from CheMed (CheMed123)\n",
      "‚úÖ Scraped 100 messages from Lobelia pharmacy and cosmetics (lobelia4cosmetics)\n",
      "‚úÖ Scraped 100 messages from ·ã®·å§·äì ·ãà·åç - ·ã®·å§·äì ·àò·à®·åÉ (yetenaweg)\n",
      "‚úÖ Scraped 100 messages from ETHIO-AMERICAN MEDICAL TRAININGS( CPD ) & HEALTH CONSULTANCY CENTER (EAHCI)\n",
      "üìå Messages saved successfully!\n",
      "üöÄ Starting image scraping...\n",
      "‚úÖ Image saved: _CheMed123_2023-02-10_12-23-06.jpg\n",
      "‚úÖ Image saved: _CheMed123_2023-02-02_08-58-52.jpg\n",
      "‚úÖ Image saved: _CheMed123_2023-02-01_08-59-37.jpg\n",
      "‚úÖ Image saved: _CheMed123_2023-01-31_09-19-53.jpg\n",
      "‚úÖ Image saved: _CheMed123_2023-01-30_09-45-25.jpg\n",
      "‚úÖ Image saved: _CheMed123_2023-01-27_07-18-40.jpg\n",
      "‚úÖ Image saved: _CheMed123_2023-01-26_18-27-53.jpg\n",
      "‚úÖ Image saved: _CheMed123_2023-01-23_10-39-20.jpg\n",
      "‚úÖ Image saved: _CheMed123_2023-01-17_08-43-12.jpg\n",
      "‚úÖ Image saved: _CheMed123_2023-01-16_13-41-35.jpg\n",
      "‚úÖ Image saved: _CheMed123_2023-01-16_10-13-42.jpg\n",
      "‚úÖ Image saved: _CheMed123_2023-01-16_09-26-09.jpg\n",
      "‚úÖ Image saved: _CheMed123_2023-01-13_12-48-47.jpg\n",
      "‚úÖ Image saved: _CheMed123_2023-01-13_09-44-14.jpg\n",
      "‚úÖ Image saved: _CheMed123_2023-01-06_16-06-21.jpg\n",
      "‚úÖ Image saved: _CheMed123_2023-01-06_09-31-17.jpg\n",
      "‚úÖ Image saved: _CheMed123_2023-01-06_06-05-01.jpg\n",
      "‚úÖ Image saved: _CheMed123_2023-01-04_05-58-02.jpg\n",
      "‚úÖ Image saved: _CheMed123_2023-01-03_17-49-48.jpg\n",
      "‚úÖ Image saved: _CheMed123_2023-01-03_05-48-34.jpg\n",
      "‚úÖ Image saved: _CheMed123_2023-01-02_07-02-55.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-12-30_15-45-35.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-12-28_17-02-08.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-12-28_06-31-50.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-12-27_17-06-32.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-12-23_06-26-15.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-12-22_06-40-25.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-12-22_03-11-26.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-12-21_15-13-27.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-12-20_17-25-05.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-12-20_11-28-59.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-12-20_07-41-33.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-12-16_12-21-01.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-12-13_05-55-18.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-12-09_12-28-53.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-12-09_04-09-49.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-12-07_06-43-48.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-12-05_05-57-22.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-12-04_12-35-18.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-12-02_13-44-41.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-12-02_06-06-12.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-12-01_06-47-22.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-11-30_06-31-44.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-11-29_07-43-06.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-11-22_08-15-47.jpg\n",
      "‚úÖ Image saved: _CheMed123_2022-11-15_11-51-16.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_14-11-12.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_14-11-11.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_14-11-11.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_14-11-11.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_13-04-17.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_13-04-01.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_09-07-32.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_09-07-32.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-30.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-30.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-30.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-30.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-30.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-30.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-30.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-30.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-30.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-30.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-30.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-30.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-30.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-30.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-30.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-30.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-30.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-30.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-29.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-29.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-29.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-30_06-32-29.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-29_13-01-26.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-29_13-01-26.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-29_13-01-26.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-29_13-01-26.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-29_13-01-26.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-29_13-01-26.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-29_13-01-26.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-29_13-01-26.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-29_12-59-56.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-29_05-03-04.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-29_05-03-03.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-29_05-03-03.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-29_05-03-03.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-29_05-03-03.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-29_05-03-03.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-29_05-03-03.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-29_05-02-10.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-28_14-36-31.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-28_14-36-31.jpg\n",
      "‚úÖ Image saved: _lobelia4cosmetics_2025-01-28_14-36-31.jpg\n",
      "üéâ Scraping process completed!\n"
     ]
    }
   ],
   "source": [
    "# Run the scrapers\n",
    "async def main():\n",
    "    \"\"\"Runs both message and image scraping.\"\"\"\n",
    "    async with client:\n",
    "        print(\"üöÄ Starting message scraping...\")\n",
    "        await scrape_messages()\n",
    "\n",
    "        print(\"üöÄ Starting image scraping...\")\n",
    "        await scrape_images()\n",
    "\n",
    "    print(\"üéâ Scraping process completed!\")\n",
    "\n",
    "# Run the async function properly\n",
    "await main()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ethiopian-medical-data-warehouse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
